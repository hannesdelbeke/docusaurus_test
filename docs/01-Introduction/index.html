<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.fd17476c3">
<link rel="alternate" type="application/rss+xml" href="/docusaurus_test/blog/rss.xml" title="DEV NOTES Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/docusaurus_test/blog/atom.xml" title="DEV NOTES Blog Atom Feed"><title data-react-helmet="true">01-Introduction | DEV NOTES</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="01-Introduction | DEV NOTES"><meta data-react-helmet="true" name="description" content="Introduction"><meta data-react-helmet="true" property="og:description" content="Introduction"><meta data-react-helmet="true" property="og:url" content="https://hannesdelbeke.github.io//docusaurus_test/docs/01-Introduction"><link data-react-helmet="true" rel="shortcut icon" href="/docusaurus_test/images/CookbookCover.jpg"><link data-react-helmet="true" rel="alternate" href="https://hannesdelbeke.github.io//docusaurus_test/docs/01-Introduction" hreflang="x-default"><link data-react-helmet="true" rel="canonical" href="https://hannesdelbeke.github.io//docusaurus_test/docs/01-Introduction"><link rel="stylesheet" href="/docusaurus_test/assets/css/styles.5ba6ab3f.css">
<link rel="preload" href="/docusaurus_test/assets/js/styles.90310086.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/runtime~main.41123567.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/main.cfe43c40.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/1.71e616a8.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/2.8534457b.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/17.cd17bc36.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/18.e886f0bf.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/935f2afb.e12ab4b3.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/17896441.ab04489d.js" as="script">
<link rel="preload" href="/docusaurus_test/assets/js/f5648033.27d7ae90.js" as="script">
</head>
<body>
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?e("light"):e("dark")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_1oUP">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/docusaurus_test/"></a></div><div class="navbar__items navbar__items--right"><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_GrZ2"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/docusaurus_test/"></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_31aa"><div class="docSidebarContainer_3Kbt" role="complementary"><div class="sidebar_15mo"><div class="menu menu--responsive thin-scrollbar menu_Bmed"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Data Engineering</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docusaurus_test/docs/01-Introduction">01-Introduction</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/02-BasicSkills">02-BasicSkills</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/03-AdvancedSkills">03-AdvancedSkills</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/04-HandsOnCourse">04-HandsOnCourse</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/05-CaseStudies">05-CaseStudies</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/06-BestPracticesCloud">06-BestPracticesCloud</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/07-DataSources">07-DataSources</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/08-InterviewQuestions">08-InterviewQuestions</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docusaurus_test/docs/09-BooksAndCourses">09-BooksAndCourses</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3ufF"><div class="container padding-vert--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><header><h1 class="docTitle_3a4h">01-Introduction</h1></header><div class="markdown"><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h1><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="contents"></a>Contents<a class="hash-link" href="#contents" title="Direct link to heading">#</a></h2><ul><li><a href="/docusaurus_test/docs/01-Introduction#what-is-this-cookbook">What is this Cookbook</a></li><li><a href="/docusaurus_test/docs/01-Introduction#data-engineer-vs-data-scientist">Data Engineer vs Data Scientist</a><ul><li><a href="/docusaurus_test/docs/01-Introduction#data-engineer">Data Engineer</a></li><li><a href="/docusaurus_test/docs/01-Introduction#data-scientist">Data Scientist</a></li><li><a href="/docusaurus_test/docs/01-Introduction#machine-learning-workflow">Machine Learning Workflow</a></li><li><a href="/docusaurus_test/docs/01-Introduction#machine-learning-model-and-data">Machine Learning Model and Data</a></li></ul></li><li><a href="/docusaurus_test/docs/01-Introduction#my-data-science-platform-blueprint">My Data Science Platform Blueprint</a><ul><li><a href="/docusaurus_test/docs/01-Introduction#connect">Connect</a></li><li><a href="/docusaurus_test/docs/01-Introduction#buffer">Buffer</a></li><li><a href="/docusaurus_test/docs/01-Introduction#processing-framework">Processing Framework</a></li><li><a href="/docusaurus_test/docs/01-Introduction#store">Store</a></li><li><a href="/docusaurus_test/docs/01-Introduction#visualize">Visualize</a></li></ul></li><li><a href="/docusaurus_test/docs/01-Introduction#who-companies-need">Who Companies Need</a></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="what-is-this-cookbook"></a>What is this Cookbook<a class="hash-link" href="#what-is-this-cookbook" title="Direct link to heading">#</a></h2><p>[test] test</p><p>I get asked a lot:
&quot;What do you actually need to learn to become an awesome data engineer?&quot;</p><p>Well, look no further. you&#x27;ll find it here!</p><p>If you are looking for AI algorithms and such data scientist things,
this book is not for you.</p><p><strong>How to use this Cookbook:</strong>
This book is intended to be a starting point for you. It is not a training! I want to help you to identify the topics to look into and becoming an awesome data engineer in the process.</p><p>It hinges on my Data Science Platform Blueprint, check it out below. Once you understand it, you can find in the book tools that fit into each key area of a Data Science platform (Connect, Buffer, Processing Framework, Store, Visualize).</p><p>Select a few tools you are interested in, research and work with them.</p><p>Don&#x27;t learn everything in this book! Focus.</p><p><strong>What types of content are in this book?</strong>
You are going to find five types of content in this book: Articles
I wrote, links to my podcast episodes (video &amp; audio), more than 200
links to helpful websites I like, data engineering interview questions
and case studies.</p><p><strong>This book is a work in progress!</strong>
As you can see, this book is not finished. I&#x27;m constantly adding new
stuff and doing videos for the topics. But obviously, because I do this
as a hobby my time is limited. You can help making this book even
better.</p><p><strong>Help make this book awesome!</strong>
If you have some cool links or topics for the cookbook, please become a
contributor on GitHub: <a href="https://github.com/andkret/Cookbook" target="_blank" rel="noopener noreferrer">https://github.com/andkret/Cookbook</a>. Fork the
repo, add them and create a pull request. Or join the discussion by
opening Issues. Tell me your thoughts, what you value,
what you think should be included, or correct me where I am wrong.
You can also write me an email any time to
plumbersofdatascience\@gmail.com anytime.</p><p><strong>This Cookbook is and will always be free!</strong>
I don&#x27;t want to sell you this book, but please support what you like and
join my Patreon: <a href="https://www.patreon.com/plumbersofds" target="_blank" rel="noopener noreferrer">https://www.patreon.com/plumbersofds</a>.
Or send me a message and support through PayPal: <a href="https://paypal.me/feedthestream" target="_blank" rel="noopener noreferrer">https://paypal.me/feedthestream</a></p><p>Check out this podcast episode where I talk in detail why I decided to
share all this information for free: <a href="https://youtu.be/k1bS5aSPos8" target="_blank" rel="noopener noreferrer">#079 Trying to stay true to
myself and making the cookbook public on
GitHub</a></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="if-you-like-this-book--need-more-help"></a>If You Like This Book &amp; Need More Help:<a class="hash-link" href="#if-you-like-this-book--need-more-help" title="Direct link to heading">#</a></h2><p>Check out my Data Engineering Academy and personal Coaching at LearnDataEngineering.com</p><p><strong>Visit learndataengineering.com:</strong> <a href="https://learndataengineering.com" target="_blank" rel="noopener noreferrer">Click Here</a></p><ul><li>New content every week!</li><li>Step by step course from researching job postings, creating and doing your project to job application tips</li><li>Full AWS Data Engineering example project (Azure in development)</li><li>1+ hours Ultimate Introduction to Data Engineering course</li><li>Data Engineering Fundamentals course</li><li>Data Platform &amp; Pipeline Design course</li><li>Apache Spark Fundamentals course</li><li>Choosing Data Stores Course</li><li>Private Member Slack Workspace (lifetime access)</li><li>Weekly Q&amp;A live stream &amp; Archive</li><li>Currently over 24 hours of videos</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="support-this-book-for-free"></a>Support This Book For Free!<a class="hash-link" href="#support-this-book-for-free" title="Direct link to heading">#</a></h2><ul><li><strong>Amazon:</strong> <a href="https://www.amazon.com/shop/plumbersofdatascience" target="_blank" rel="noopener noreferrer">Click Here</a> buy whatever you like from Amazon using this link* (Also check out my complete podcast gear and books)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="how-to-contribute"></a>How To Contribute<a class="hash-link" href="#how-to-contribute" title="Direct link to heading">#</a></h2><p>If you have some cool links or topics for the cookbook, please become a contributor.</p><p>Simply pull the repo, add your ideas and create a pull request.
You can also open an issue and put your thoughts there.</p><p>Please use the &quot;Issues&quot; function for comments.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="data-engineer-vs-data-scientist"></a>Data Engineer vs Data Scientist<a class="hash-link" href="#data-engineer-vs-data-scientist" title="Direct link to heading">#</a></h2><p>| Podcast Episode: #050 Data Engineer, Scientist or Analyst - Which One Is For You?
|-----------------------------------------------------------------------------------
| In this podcast we talk about the diï¬€erences between data scientists, analysts and engineers. Which are the three main data science jobs. All three are super important. This makes it easy to decide
| <a href="https://youtu.be/64TYZETOEdQ" target="_blank" rel="noopener noreferrer">Watch on YouTube</a> \ <a href="https://anchor.fm/andreaskayy/episodes/050-Data-Engineer-Scientist-or-Analyst-Which-One-Is-For-You-e45ibl" target="_blank" rel="noopener noreferrer">Listen on Anchor</a></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="data-engineer"></a>Data Engineer<a class="hash-link" href="#data-engineer" title="Direct link to heading">#</a></h3><p>Data Engineers are the link between the management&#x27;s data strategy
and the data scientists that need to work with data.</p><p>What they do is building the platforms that enable data scientists to do
their magic.</p><p>These platforms are usually used in five different ways:</p><ul><li><p>Data ingestion and storage of large amounts of data</p></li><li><p>Algorithm creation by data scientists</p></li><li><p>Automation of the data scientist&#x27;s machine learning models and
algorithms for production use</p></li><li><p>Data visualization for employees and customers</p></li><li><p>Most of the time these guys start as traditional solution architects
for systems that involve SQL databases, web servers, SAP
installations and other &quot;standard&quot; systems.</p></li></ul><p>But to create big data platforms the engineer needs to be an expert in
specifying, setting up and maintaining big data technologies like:
Hadoop, Spark, HBase, Cassandra, MongoDB, Kafka, Redis and more.</p><p>What they also need is experience on how to deploy systems on cloud
infrastructure like at Amazon or Google or on-premise hardware.</p><p>| Podcast Episode: #048 From Wannabe Data Scientist To Engineer My Journey
|------------------|
|In this episode Kate Strachnyi interviews me for her humans of data science podcast. We talk about how I found out that I am more into the engineering part of data science.<br>
| <a href="https://youtu.be/pIZkTuN5AMM" target="_blank" rel="noopener noreferrer">Watch on YouTube</a> \ <a href="https://anchor.fm/andreaskayy/episodes/048-From-Wannabe-Data-Scientist-To-Engineer-My-Journey-e45i2o" target="_blank" rel="noopener noreferrer">Listen on Anchor</a>|</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="data-scientist"></a>Data Scientist<a class="hash-link" href="#data-scientist" title="Direct link to heading">#</a></h3><p>Data scientists aren&#x27;t like every other scientist.</p><p>Data scientists do not wear white coats or work in high tech labs full
of science fiction movie equipment. They work in offices just like you
and me.</p><p>What differs them from most of us is that they are math experts. They
use linear algebra and multivariable calculus to create new insight from
existing data.</p><p>How exactly does this insight look?</p><p>Here&#x27;s an example:</p><p>An industrial company produces a lot of products that need to be tested
before shipping.</p><p>Usually such tests take a lot of time because there are hundreds of
things to be tested. All to make sure that your product is not broken.</p><p>Wouldn&#x27;t it be great to know early if a test fails ten steps down the
line? If you knew that you could skip the other tests and just trash the
product or repair it.</p><p>That&#x27;s exactly where a data scientist can help you, big-time. This field
is called predictive analytics and the technique of choice is machine
learning.</p><p>Machine what? Learning?</p><p>Yes, machine learning, it works like this:</p><p>You feed an algorithm with measurement data. It generates a model and
optimises it based on the data you fed it with. That model basically
represents a pattern of how your data is looking. You show that model
new data and the model will tell you if the data still represents the
data you have trained it with. This technique can also be used for
predicting machine failure in advance with machine learning. Of course
the whole process is not that simple.</p><p>The actual process of training and applying a model is not that hard. A
lot of work for the data scientist is to figure out how to pre-process
the data that gets fed to the algorithms.</p><p>In order to train an algorithm you need useful data. If you use any data
for the training the produced model will be very unreliable.</p><p>An unreliable model for predicting machine failure would tell you that
your machine is damaged even if it is not. Or even worse: It would tell
you the machine is ok even when there is a malfunction.</p><p>Model outputs are very abstract. You also need to post-process the model
outputs to receive the outputs you desire</p><p><img alt="The Machine Learning Pipeline" src="/docusaurus_test/assets/images/Machine-Learning-Pipeline-50e2b2ce422de5950854804520dbe4cf.jpg"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="machine-learning-workflow"></a>Machine Learning Workflow<a class="hash-link" href="#machine-learning-workflow" title="Direct link to heading">#</a></h3><p><img alt="The Machine Learning Workflow" src="/docusaurus_test/assets/images/Machine-Learning-Workflow-af7d8dc7561028d9eddcb2b7dfdfe4e0.jpg"></p><p>Data Scientists and Data Engineers. How does that all fit together?</p><p>You have to look at the data science process. How stuff is created and how data
science is done. How machine learning is
done.</p><p>The machine learning process shows, that you start with a training phase. A phase where you are basically training the algorithms to create the right output.</p><p>In the learning phase you are having the input parameters. Basically the configuration of the model and you have the input data.</p><p>What you&#x27;re doing is you are training the algorithm. While training the algorithm modifies the training
parameters. It also modifies the used data and then you are getting to an output.</p><p>Once you get an output you are evaluating. Is that output okay, or is that output not the desired output?</p><p>if the output is not what you were looking for? Then you are continuing with the training phase.</p><p>You&#x27;re trying to retrain the model hundreds, thousands, hundred thousands of times. Of course all this is being done automatically.</p><p>Once you are satisfied with the output, you are putting the model into production. In production it is no longer fed with training
data it&#x27;s fed with the live data.</p><p>It&#x27;s evaluating the input data live and putting out live results.</p><p>So, you went from training to production and then what?</p><p>What you do is monitoring the output. If the output keeps making sense, all good!</p><p>If the output of the model changes and it&#x27;s on longer what you have expected, it means the model doesn&#x27;t work anymore.</p><p>You need to trigger a retraining of the model. It basically gets to getting trained again.</p><p>Once you are again satisfied with the output, you put it into production again. It replaces the one in production.</p><p>This is the overall process how machine learning. It&#x27;s how the learning part of data science is working.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="machine-learning-model-and-data"></a>Machine Learning Model and Data<a class="hash-link" href="#machine-learning-model-and-data" title="Direct link to heading">#</a></h3><p><img alt="The Machine Learning Model" src="/docusaurus_test/assets/images/Machine-Learning-Model-2fd98ba21952a6da106c9f626a63de54.jpg"></p><p>Now that&#x27;s all very nice.</p><p>When you look at it, you have two very important places where you have data.</p><p>You have in the training phase two types of data:
Data that you use for the training. Data that basically configures the model, the hyper parameter configuration.</p><p>Once you&#x27;re in production you have the live data that is streaming in. Data that is coming in from from an app, from
a IoT device, logs, or whatever.</p><p>A data catalog is also important. It explains which features are available and how different data sets are labeled.</p><p>All different types of data. Now, here comes the engineering part.</p><p>The Data Engineers part, is making this data available. Available to the data scientist and the machine learning process.</p><p>So when you look at the model, on the left side you have your hyper parameter configuration. You need to store and manage these configurations somehow.</p><p>Then you have the actual training data.</p><p>There&#x27;s a lot going on with the training data:</p><p>Where does it come from? Who owns it? Which is basically data governance.</p><p>What&#x27;s the lineage? Have you modified this data? What did you do, what was the basis, the raw data?</p><p>You need to access all this data somehow. In training and in production.</p><p>In production you need to have access to the live data.</p><p>All this is the data engineers job. Making the data available.</p><p>First an architect needs to build the platform. This can also be a good data engineer.</p><p>Then the data engineer needs to build the pipelines. How is the data coming in and how is the platform
connecting to other systems.</p><p>How is that data then put into the storage. Is there a pre processing for the algorithms necessary? He&#x27;ll do it.</p><p>Once the data and the systems are available, it&#x27;s time for the machine learning part.</p><p>It is ready for processing. Basically ready for the data scientist.</p><p>Once the analytics is done the data engineer needs to build pipelines to make it then accessible again. For instance for other analytics processes, for APIs, for front ends and so on.</p><p>All in all, the data engineer&#x27;s part is a computer science part.</p><p>That&#x27;s why I love it so much :)</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="my-data-science-platform-blueprint"></a>My Data Science Platform Blueprint<a class="hash-link" href="#my-data-science-platform-blueprint" title="Direct link to heading">#</a></h2><p>I have created a simple and modular big data platform
blueprint. It is based on what I have seen in the field and
read in tech blogs all over the internet.</p><p>Why do I believe it will be super useful to you?</p><p>Because, unlike other blueprints it is not focused on technology.</p><p>Following my blueprint will allow you to create the big data platform
that fits exactly your needs. Building the perfect platform will allow
data scientists to discover new insights.</p><p>It will enable you to perfectly handle big data and allow you to make
data driven decisions.</p><p>The blueprint is focused on the five key areas: Connect, Buffer, Processing Frameworks, Store and Visualize.</p><p><img alt="Data Science Platform Blueprint" src="/docusaurus_test/assets/images/Data-Science-Blueprint-New-0d2ae636eca9abb0a36e777467ca0a5e.jpg"></p><p>Having the platform split like this turns it into a modular platform with
loosely coupled interfaces.</p><p>Why is it so important to have a modular platform?</p><p>If you have a platform that is not modular you end up with something
that is fixed or hard to modify. This means you can not adjust the
platform to changing requirements of the company.</p><p>Because of modularity it is possible to specifically select tools for your use case. It also allows you to replace every component, if you need it.</p><p>Now, lets talk more about each key area.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="connect"></a>Connect<a class="hash-link" href="#connect" title="Direct link to heading">#</a></h3><p>Ingestion is all about getting the data in from the source and making it
available to later stages. Sources can be everything from tweets, server
logs to IoT sensor data (e.g. from cars).</p><p>Sources send data to your API Services. The API is going to push the
data into a temporary storage.</p><p>The temporary storage allows other stages simple and fast access to
incoming data.</p><p>A great solution is to use messaging queue systems like Apache Kafka,
RabbitMQ or AWS Kinesis. Sometimes people also use caches for
specialised applications like Redis.</p><p>A good practice is that the temporary storage follows the
publish-subscribe pattern. This way APIs can publish messages and
Analytics can quickly consume them.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="buffer"></a>Buffer<a class="hash-link" href="#buffer" title="Direct link to heading">#</a></h3><p>In the buffer phase you have pub/sub systems like Apache Kafka, Redis, or other Cloud tools like Google pub/sub or AWS Kinesis.</p><p>These systems are more or less message Queues.
You put something in on one side and take it out on the other.</p><p>The idea behind buffers is to have an intermediate system for the incoming data.</p><p>How this works is, for instance you&#x27;re getting data in from from an API.
The API is publishing into the message queue. Data is buffered there until it is picked up by the processing.</p><p>If you don&#x27;t have a buffer you can run into problems when writing directly into a store, or you&#x27;re processing the data directly. You can always have peaks of incoming data that stall the systems.</p><p>Like, it&#x27;s lunch break and people are working with your app way more then usually.
There&#x27;s more data coming in very very fast. Faster than the analytics of the storage can handle.</p><p>In this case you would run into problems, because the whole system would stall. It would therefore take long to process the data and your customers would be annoyed.</p><p>With a buffer you&#x27;re buffering the incoming data. Processes for storage and analytics can take out only as much data as they can process. You are no longer in danger of overpowering systems.</p><p>Buffers are also really good for building pipelines.</p><p>You take data out of Kafka, you pre-process it and put it back into Kafka.
Then with another analytics process you take the processed data back out and put it into a store.</p><p>Ta Da! A pipeline.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="processing-framework"></a>Processing Framework<a class="hash-link" href="#processing-framework" title="Direct link to heading">#</a></h3><p>The analyse stage is where the actual analytics is done. Analytics, in
the form of stream and batch processing.</p><p>Streaming data is taken from ingest and fed into analytics. Streaming
analyses the &quot;live&quot; data, thus generating fast results.</p><p>As the central and most important stage, analytics also has access to
the big data storage. Because of that connection, analytics can take a
big chunk of data and analyse it.</p><p>This type of analysis is called batch processing. It will deliver you
answers for the big questions.</p><p>For a short video about batch and stream processing and their use-cases, click on the link below:</p><p><a href="https://www.youtube.com/watch?v=o-aGi3FmdfU" target="_blank" rel="noopener noreferrer">Adding Batch to a Streaming Pipeline</a></p><p>The analytics process, batch or streaming, is not a one way process.
Analytics can also write data back to the big data storage.</p><p>Often times writing data back to the storage makes sense. It allows you
to combine previous analytics outputs with the raw data.</p><p>Analytics give insights when you combine
raw data. This combination will often times allow you to create even more
useful insights.</p><p>A wide variety of analytics tools are available. Ranging from MapReduce
or AWS Elastic MapReduce to Apache Spark and AWS lambda.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="store"></a>Store<a class="hash-link" href="#store" title="Direct link to heading">#</a></h3><p>This is the typical big data storage where you just store everything. It
enables you to analyse the big picture.</p><p>Most of the data might seem useless for now, but it is of upmost
importance to keep it. Throwing data away is a big no no.</p><p>Why not throw something away when it is useless?</p><p>Although it seems useless for now, data scientists can work with the
data. They might find new ways to analyse the data and generate valuable
insights from it.</p><p>What kind of systems can be used to store big data?</p><p>Systems like Hadoop HDFS, Hbase, Amazon S3 or DynamoDB are a perfect fit
to store big data.</p><p>Check out my podcast how to decide between SQL and NoSQL:
<a href="https://anchor.fm/andreaskayy/embed/episodes/NoSQL-Vs-SQL-How-To-Choose-e12f1o" target="_blank" rel="noopener noreferrer">https://anchor.fm/andreaskayy/embed/episodes/NoSQL-Vs-SQL-How-To-Choose-e12f1o</a></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="visualize"></a>Visualize<a class="hash-link" href="#visualize" title="Direct link to heading">#</a></h3><p>Displaying data is as important as ingesting, storing and analysing it.
Visualizations enable business users to make data driven decisions.</p><p>This is why it is important to have a good visual presentation of the
data. Sometimes you have a lot of different use cases or projects using
the platform.</p><p>It might not be possible for you to build the perfect UI that fits
everyone needs. What you should do in this case is enable others to build the
perfect UI themselves.</p><p>How to do that? By creating APIs to access the data and making them
available to developers.</p><p>Either way, UI or API the trick is to give the display stage direct
access to the data in the big data cluster. This kind of access will
allow the developers to use analytics results as well as raw data to
build the perfect application.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="who-companies-need"></a>Who Companies Need<a class="hash-link" href="#who-companies-need" title="Direct link to heading">#</a></h2><p>For a company, it is important to have well-trained data
engineers and data scientists. Think of the data scientist as a
professional race car driver. A fit athlete with talent and driving
skills like you have never seen before.</p><p>What he needs to win races is someone who will provide him the perfect
race car to drive. It is the data engineer/solution architect who will design and built the race car.</p><p>Like the driver and the race car engineer, the data scientist and the data engineer need to work closely together. They need to know the different big data tools inside out.</p><p>That&#x27;s why companies are looking for people with Spark experience. Spark is the common ground between the data engineer and the data scientist that drives innovation.</p><p>Spark gives data scientists the tools to do analytics and helps
engineers to bring the data scientist&#x27;s algorithms into production.
After all, those two decide how good the data platform is, how good the
analytics insight is and how fast the whole system gets into a
production-ready state.</p></div></article><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docusaurus_test/docs/02-BasicSkills"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">02-BasicSkills Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#contents" class="table-of-contents__link">Contents</a></li><li><a href="#what-is-this-cookbook" class="table-of-contents__link">What is this Cookbook</a></li><li><a href="#if-you-like-this-book--need-more-help" class="table-of-contents__link">If You Like This Book &amp; Need More Help:</a></li><li><a href="#support-this-book-for-free" class="table-of-contents__link">Support This Book For Free!</a></li><li><a href="#how-to-contribute" class="table-of-contents__link">How To Contribute</a></li><li><a href="#data-engineer-vs-data-scientist" class="table-of-contents__link">Data Engineer vs Data Scientist</a><ul><li><a href="#data-engineer" class="table-of-contents__link">Data Engineer</a></li><li><a href="#data-scientist" class="table-of-contents__link">Data Scientist</a></li><li><a href="#machine-learning-workflow" class="table-of-contents__link">Machine Learning Workflow</a></li><li><a href="#machine-learning-model-and-data" class="table-of-contents__link">Machine Learning Model and Data</a></li></ul></li><li><a href="#my-data-science-platform-blueprint" class="table-of-contents__link">My Data Science Platform Blueprint</a><ul><li><a href="#connect" class="table-of-contents__link">Connect</a></li><li><a href="#buffer" class="table-of-contents__link">Buffer</a></li><li><a href="#processing-framework" class="table-of-contents__link">Processing Framework</a></li><li><a href="#store" class="table-of-contents__link">Store</a></li><li><a href="#visualize" class="table-of-contents__link">Visualize</a></li></ul></li><li><a href="#who-companies-need" class="table-of-contents__link">Who Companies Need</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/docusaurus_test/assets/js/styles.90310086.js"></script>
<script src="/docusaurus_test/assets/js/runtime~main.41123567.js"></script>
<script src="/docusaurus_test/assets/js/main.cfe43c40.js"></script>
<script src="/docusaurus_test/assets/js/1.71e616a8.js"></script>
<script src="/docusaurus_test/assets/js/2.8534457b.js"></script>
<script src="/docusaurus_test/assets/js/17.cd17bc36.js"></script>
<script src="/docusaurus_test/assets/js/18.e886f0bf.js"></script>
<script src="/docusaurus_test/assets/js/935f2afb.e12ab4b3.js"></script>
<script src="/docusaurus_test/assets/js/17896441.ab04489d.js"></script>
<script src="/docusaurus_test/assets/js/f5648033.27d7ae90.js"></script>
</body>
</html>